{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies in Colab\n",
        "!pip install transformers datasets torch pandas nltk gradio"
      ],
      "metadata": {
        "id": "_HaWFudhe00h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoMyGYIIeVTK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import os\n",
        "from datetime import datetime\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# Set random seed based on current time for varied outputs\n",
        "random.seed(int(datetime.now().timestamp()))"
      ],
      "metadata": {
        "id": "Eoak33pbeyLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define themes and sample data\n",
        "THEMES = [\"career_advice\", \"industry_insights\", \"personal_achievement\"]\n",
        "TOPICS = [\"career growth\", \"work-life balance\", \"leadership\", \"productivity\", \"team collaboration\", \"innovation\"]\n",
        "INDUSTRIES = [\"tech\", \"finance\", \"healthcare\", \"education\", \"marketing\", \"consulting\"]\n",
        "ACHIEVEMENTS = [\"a promotion\", \"completing a major project\", \"earning a certification\", \"leading a successful team\", \"launching a new product\"]\n",
        "SUPPORT = [\"my team\", \"my mentors\", \"my colleagues\", \"my network\", \"my community\"]\n",
        "INTRO_PHRASES = [\"Excited to share\", \"Thrilled to reflect on\", \"Proud to discuss\", \"Inspired to talk about\", \"Happy to highlight\"]\n",
        "CALL_TO_ACTIONS = [\"Share your thoughts below!\", \"What’s your take?\", \"Let’s discuss in the comments!\", \"Tell me your story!\", \"Join the conversation!\"]\n",
        "LESSONS = [\"dedication\", \"collaboration\", \"continuous learning\", \"resilience\", \"adaptability\"]\n",
        "OBSERVATIONS = [\"New tools are emerging\", \"Collaboration is key\", \"Adaptability is crucial\", \"Data-driven decisions are shaping the future\"]"
      ],
      "metadata": {
        "id": "w7Fx19lSe5d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get synonyms with filtering for professional tone\n",
        "def get_synonym(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonym = lemma.name().replace('_', ' ')\n",
        "            if len(synonym.split()) == 1 and synonym.isalpha() and len(synonym) > 3:\n",
        "                synonyms.add(synonym)\n",
        "    return random.choice(list(synonyms)) if synonyms else word"
      ],
      "metadata": {
        "id": "c2n57G8ffHbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic dataset\n",
        "def generate_synthetic_dataset(num_samples=1000):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        theme = random.choice(THEMES)\n",
        "        intro = random.choice(INTRO_PHRASES)\n",
        "        cta = random.choice(CALL_TO_ACTIONS)\n",
        "        if theme == \"career_advice\":\n",
        "            topic = random.choice(TOPICS)\n",
        "            industry = random.choice(INDUSTRIES)\n",
        "            prompt = random.choice([\n",
        "                f\"Write a LinkedIn post about {topic} in the {industry} field.\",\n",
        "                f\"Share a professional LinkedIn post on {topic} for {industry} professionals.\"\n",
        "            ])\n",
        "            post = f\"{intro} my insights on {topic} in {industry}! {get_synonym('success')} stems from {random.choice(LESSONS)}. {random.choice(['Here’s what I’ve learned:', 'My key takeaway:'])} {get_synonym('effort')} pays off. {cta} #{get_synonym('career')}Growth\"\n",
        "        elif theme == \"industry_insights\":\n",
        "            industry = random.choice(INDUSTRIES)\n",
        "            prompt = random.choice([\n",
        "                f\"Write a LinkedIn post about trends in the {industry} industry.\",\n",
        "                f\"Create a LinkedIn post discussing innovations in {industry}.\"\n",
        "            ])\n",
        "            post = f\"{intro} the latest trends in {industry}! {get_synonym('innovation')} is reshaping the field. {random.choice(OBSERVATIONS)} {cta} #{get_synonym('industry')}Trends\"\n",
        "        else:  # personal_achievement\n",
        "            achievement = random.choice(ACHIEVEMENTS)\n",
        "            prompt = random.choice([\n",
        "                f\"Write a LinkedIn post about achieving {achievement}.\",\n",
        "                f\"Share a LinkedIn post celebrating {achievement}.\"\n",
        "            ])\n",
        "            post = f\"{intro} my {achievement}! This journey taught me {get_synonym('perseverance')}. Grateful for {random.choice(SUPPORT)}. {random.choice(['What’s your latest milestone?', 'How do you celebrate success?'])} {cta} #{get_synonym('success')}Story\"\n",
        "        data.append({\"prompt\": prompt, \"post\": post})\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "_I_47i3rfM0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataset for Hugging Face\n",
        "def prepare_dataset(df):\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\", local_files_only=False)  # Allow initial download in Colab\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        inputs = [f\"{prompt} ### {post}\" for prompt, post in zip(examples[\"prompt\"], examples[\"post\"])]\n",
        "        tokenized = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=128)\n",
        "        tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "        return tokenized\n",
        "\n",
        "    return dataset.map(tokenize_function, batched=True), tokenizer"
      ],
      "metadata": {
        "id": "u1XTCOvVfN_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "def fine_tune_model(dataset, tokenizer, output_dir=\"/content/linkedin_model\"):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", local_files_only=False)  # Allow initial download\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,\n",
        "        save_steps=500,\n",
        "        save_total_limit=2,\n",
        "        logging_steps=100,\n",
        "        learning_rate=2e-5,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset\n",
        "    )\n",
        "    trainer.train()\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "5ulnvt5AfTc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a LinkedIn post\n",
        "def generate_linkedin_post(theme, field=None, achievement=None, tokenizer=None, model=None):\n",
        "    model_path = \"/content/linkedin_model\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model not found at {model_path}. Please fine-tune the model first.\")\n",
        "\n",
        "    if tokenizer is None or model is None:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
        "\n",
        "    prompt_variants = {\n",
        "        \"career_advice\": [\n",
        "            f\"Write a LinkedIn post about {random.choice(TOPICS)} in the {field or random.choice(INDUSTRIES)} field.\",\n",
        "            f\"Share a professional LinkedIn post on {random.choice(TOPICS)} for {field or random.choice(INDUSTRIES)} professionals.\"\n",
        "        ],\n",
        "        \"industry_insights\": [\n",
        "            f\"Write a LinkedIn post about trends in the {field or random.choice(INDUSTRIES)} industry.\",\n",
        "            f\"Create a LinkedIn post discussing innovations in {field or random.choice(INDUSTRIES)}.\"\n",
        "        ],\n",
        "        \"personal_achievement\": [\n",
        "            f\"Write a LinkedIn post about achieving {achievement or random.choice(ACHIEVEMENTS)}.\",\n",
        "            f\"Share a LinkedIn post celebrating {achievement or random.choice(ACHIEVEMENTS)}.\"\n",
        "        ]\n",
        "    }\n",
        "    prompt = random.choice(prompt_variants.get(theme, prompt_variants[\"career_advice\"]))\n",
        "\n",
        "    torch.manual_seed(int(datetime.now().timestamp()))\n",
        "\n",
        "    inputs = tokenizer(f\"{prompt} ###\", return_tensors=\"pt\", padding=True, truncation=True, max_length=50)\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=100,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.85,\n",
        "        temperature=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    post = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"###\")[-1].strip()\n",
        "    post = post[0].upper() + post[1:] + ('.' if not post.endswith('.') else '')\n",
        "    for word, replacement in [(\"succeeder\", \"success\"), (\"tenaciousness\", \"persistence\"), (\"ontogenesis\", \"growth\")]:\n",
        "        post = post.replace(word, replacement)\n",
        "    if theme == \"career_advice\":\n",
        "        post = post.replace(\"#CareerGrowth\", f\"#{get_synonym('career')}Growth\")\n",
        "    elif theme == \"industry_insights\":\n",
        "        post = post.replace(\"#IndustryTrends\", f\"#{get_synonym('industry')}Trends\")\n",
        "    else:\n",
        "        post = post.replace(\"#SuccessStory\", f\"#{get_synonym('success')}Story\")\n",
        "    return post"
      ],
      "metadata": {
        "id": "_SDJemY_fai7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "def gradio_generate_post(theme, field, achievement):\n",
        "    try:\n",
        "        post = generate_linkedin_post(theme, field if field else None, achievement if achievement else None)\n",
        "        return post\n",
        "    except FileNotFoundError:\n",
        "        return \"Model not found. Please run the fine-tuning step first by executing the cell above.\"\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as interface:\n",
        "    gr.Markdown(\"# LinkedIn Post Generator\")\n",
        "    gr.Markdown(\"Select a theme and provide optional inputs to generate a professional LinkedIn post.\")\n",
        "    theme = gr.Dropdown(choices=THEMES, label=\"Theme\", value=\"career_advice\")\n",
        "    field = gr.Textbox(label=\"Industry (optional, e.g., tech, finance)\", placeholder=\"Leave blank for random\")\n",
        "    achievement = gr.Textbox(label=\"Achievement (optional, e.g., a promotion)\", placeholder=\"Leave blank for random\")\n",
        "    generate_btn = gr.Button(\"Generate Post\")\n",
        "    output = gr.Textbox(label=\"Generated Post\")\n",
        "    generate_btn.click(fn=gradio_generate_post, inputs=[theme, field, achievement], outputs=output)\n"
      ],
      "metadata": {
        "id": "qks-ix4ofgU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage and fine-tuning\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating synthetic dataset...\")\n",
        "    df = generate_synthetic_dataset(25000)\n",
        "\n",
        "    print(\"Preparing dataset...\")\n",
        "    dataset, tokenizer = prepare_dataset(df)\n",
        "\n",
        "    print(\"Fine-tuning model... (This may take ~10-20 minutes on Colab GPU)\")\n",
        "    model, tokenizer = fine_tune_model(dataset, tokenizer)\n",
        "\n",
        "    print(\"Launching Gradio interface...\")\n",
        "    interface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "gIu6MVQVfnN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}